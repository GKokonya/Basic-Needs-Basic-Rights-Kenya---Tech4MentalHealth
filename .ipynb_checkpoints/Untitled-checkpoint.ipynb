{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import cross_validate\n",
    "from nltk.corpus import wordnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Train.csv',index_col='ID')#train\n",
    "df2 = pd.read_csv('Test.csv',index_col='ID')#test\n",
    "df3 = pd.read_csv('SampleSubmission.csv')#submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SUAVK39Z</th>\n",
       "      <td>I feel that it was better I dieAm happy</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9JDAGUV3</th>\n",
       "      <td>Why do I get hallucinations?</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419WR1LQ</th>\n",
       "      <td>I am stresseed due to lack of financial suppor...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6UY7DX6Q</th>\n",
       "      <td>Why is life important?</td>\n",
       "      <td>Suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FYC0FTFB</th>\n",
       "      <td>How could I be helped to go through the depres...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text       label\n",
       "ID                                                                     \n",
       "SUAVK39Z            I feel that it was better I dieAm happy  Depression\n",
       "9JDAGUV3                       Why do I get hallucinations?       Drugs\n",
       "419WR1LQ  I am stresseed due to lack of financial suppor...  Depression\n",
       "6UY7DX6Q                             Why is life important?     Suicide\n",
       "FYC0FTFB  How could I be helped to go through the depres...  Depression"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def lemmatize_sentence(sentence):\n",
    "    #tokenize the sentence and find the POS tag for each token\n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence))\n",
    "    #tuple of (token, wordnet_tag)\n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "    lemmatized_sentence = []\n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            #if there is no available tag, append the token as is\n",
    "            lemmatized_sentence.append(word)\n",
    "        else:\n",
    "            #else use the tag to lemmatize the token\n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SUAVK39Z</th>\n",
       "      <td>I feel that it be well I dieAm happy</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9JDAGUV3</th>\n",
       "      <td>Why do I get hallucination ?</td>\n",
       "      <td>Drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419WR1LQ</th>\n",
       "      <td>I be stresseed due to lack of financial suppor...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6UY7DX6Q</th>\n",
       "      <td>Why be life important ?</td>\n",
       "      <td>Suicide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FYC0FTFB</th>\n",
       "      <td>How could I be help to go through the depressi...</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text       label\n",
       "ID                                                                     \n",
       "SUAVK39Z               I feel that it be well I dieAm happy  Depression\n",
       "9JDAGUV3                       Why do I get hallucination ?       Drugs\n",
       "419WR1LQ  I be stresseed due to lack of financial suppor...  Depression\n",
       "6UY7DX6Q                            Why be life important ?     Suicide\n",
       "FYC0FTFB  How could I be help to go through the depressi...  Depression"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizing test\n",
    "df['text'] = df['text'].apply(lambda x: lemmatize_sentence(x))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>02V56KMO</th>\n",
       "      <td>How to overcome bad feeling and emotion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03BMGTOK</th>\n",
       "      <td>I feel like give up in life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>03LZVFM6</th>\n",
       "      <td>I be so depressed feel like get no strength to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0EPULUM5</th>\n",
       "      <td>I feel so low especially since I have no one t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0GM4C5GD</th>\n",
       "      <td>can i be successful when I be a drug addict ?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                       text\n",
       "ID                                                         \n",
       "02V56KMO            How to overcome bad feeling and emotion\n",
       "03BMGTOK                        I feel like give up in life\n",
       "03LZVFM6  I be so depressed feel like get no strength to...\n",
       "0EPULUM5  I feel so low especially since I have no one t...\n",
       "0GM4C5GD      can i be successful when I be a drug addict ?"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lemmatizing test\n",
    "df2['text'] = df2['text'].apply(lambda x: lemmatize_sentence(x))\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     0\n",
       "label    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text     object\n",
       "label    object\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>616</td>\n",
       "      <td>616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>600</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>How can I stop use alcohol ?</td>\n",
       "      <td>Depression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4</td>\n",
       "      <td>352</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                text       label\n",
       "count                            616         616\n",
       "unique                           600           4\n",
       "top     How can I stop use alcohol ?  Depression\n",
       "freq                               4         352"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_process(mess):\n",
    "    \"\"\"\n",
    "    Takes in a string of text, then performs the following:\n",
    "    1. Remove all punctuation\n",
    "    2. Remove all stopwords\n",
    "    3. Returns a list of the cleaned text\n",
    "    \"\"\"\n",
    "    # Check characters to see if they are in punctuation\n",
    "    nopunc = [char for char in mess if char not in string.punctuation]\n",
    "\n",
    "    # Join the characters again to form the string.\n",
    "    nopunc = ''.join(nopunc)\n",
    "    \n",
    "    # Now just remove any stopwords\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "#binarizer = LabelBinarizer()\n",
    "#n=pd.DataFrame(binarizer.fit_transform(train['label']), columns=binarizer.classes_)\n",
    "\n",
    "binarizer = LabelBinarizer()\n",
    "binarizer.fit(df['label'])\n",
    "\n",
    "# transform target variable\n",
    "y = binarizer.transform(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# split dataset into training and validation set\n",
    "xtrain, xval, ytrain, yval = train_test_split(df['text'], y, test_size=0.2, random_state=9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TF-IDF features\n",
    "xtrain_tfidf = tfidf_vectorizer.fit_transform(xtrain)\n",
    "xval_tfidf = tfidf_vectorizer.transform(xval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Binary Relevance\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "# Performance metric\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "clf = OneVsRestClassifier(lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=LogisticRegression(C=1.0, class_weight=None,\n",
       "                                                 dual=False, fit_intercept=True,\n",
       "                                                 intercept_scaling=1,\n",
       "                                                 l1_ratio=None, max_iter=100,\n",
       "                                                 multi_class='auto',\n",
       "                                                 n_jobs=None, penalty='l2',\n",
       "                                                 random_state=None,\n",
       "                                                 solver='lbfgs', tol=0.0001,\n",
       "                                                 verbose=0, warm_start=False),\n",
       "                    n_jobs=None)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model on train data\n",
    "clf.fit(xtrain_tfidf, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make predictions for validation set\n",
    "y_pred = clf.predict(xval_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict probabilities\n",
    "y_pred_prob = clf.predict_proba(xval_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6222489472051234"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(yval,y_pred_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.09322946, 0.83646601, 0.04806058, 0.07067131],\n",
       "       [0.48411136, 0.07651113, 0.48121074, 0.03876905],\n",
       "       [0.14194427, 0.6041095 , 0.0532301 , 0.18630373],\n",
       "       [0.06850868, 0.85584826, 0.05169354, 0.08590489],\n",
       "       [0.13596486, 0.60872593, 0.09766865, 0.12068262],\n",
       "       [0.09086787, 0.76742856, 0.0776317 , 0.08687139],\n",
       "       [0.20449209, 0.61327301, 0.06547885, 0.0844596 ],\n",
       "       [0.17924914, 0.19705163, 0.44903528, 0.08695028],\n",
       "       [0.12499228, 0.67627207, 0.07990107, 0.10564281],\n",
       "       [0.0446266 , 0.93891269, 0.04055523, 0.04037506],\n",
       "       [0.43585728, 0.1581758 , 0.30109016, 0.04929691],\n",
       "       [0.61755695, 0.2486565 , 0.06621578, 0.0529369 ],\n",
       "       [0.07021517, 0.77184202, 0.05636727, 0.13246687],\n",
       "       [0.13973793, 0.39339464, 0.24196387, 0.11269012],\n",
       "       [0.12105533, 0.61906659, 0.11212967, 0.09757891],\n",
       "       [0.35572433, 0.52259512, 0.04473584, 0.08880948],\n",
       "       [0.09953467, 0.36854922, 0.05978939, 0.44106525],\n",
       "       [0.10452056, 0.80057962, 0.05528075, 0.08401562],\n",
       "       [0.57370496, 0.25042702, 0.07990466, 0.06764408],\n",
       "       [0.32537   , 0.33662636, 0.0796334 , 0.14601487],\n",
       "       [0.07033415, 0.86548405, 0.05282771, 0.05884858],\n",
       "       [0.08429466, 0.82724229, 0.05126746, 0.07671618],\n",
       "       [0.07934348, 0.81527355, 0.05660249, 0.08374689],\n",
       "       [0.08325611, 0.29356379, 0.45364533, 0.12318055],\n",
       "       [0.04811656, 0.93746356, 0.03949688, 0.03809107],\n",
       "       [0.09258587, 0.82012173, 0.03745729, 0.10006927],\n",
       "       [0.24038433, 0.740744  , 0.03531032, 0.06809456],\n",
       "       [0.16122509, 0.63974221, 0.06235407, 0.107165  ],\n",
       "       [0.14744742, 0.48519106, 0.19780474, 0.08052577],\n",
       "       [0.52682228, 0.19953858, 0.12027843, 0.08829979],\n",
       "       [0.23639158, 0.44684051, 0.14100937, 0.1002434 ],\n",
       "       [0.07735996, 0.85001269, 0.05294891, 0.07218431],\n",
       "       [0.10550112, 0.77022114, 0.09269222, 0.0690512 ],\n",
       "       [0.136223  , 0.30170091, 0.19205543, 0.2699802 ],\n",
       "       [0.28983605, 0.46619425, 0.07932862, 0.10054495],\n",
       "       [0.07324568, 0.86095634, 0.04740866, 0.06473277],\n",
       "       [0.14606748, 0.69894576, 0.11093573, 0.06055986],\n",
       "       [0.95660541, 0.03523215, 0.07261632, 0.02813703],\n",
       "       [0.15606049, 0.60636537, 0.0796859 , 0.10852117],\n",
       "       [0.0224254 , 0.97958914, 0.0270667 , 0.02430934],\n",
       "       [0.21972247, 0.25751483, 0.07614111, 0.33294938],\n",
       "       [0.13907064, 0.32347811, 0.34682381, 0.09205841],\n",
       "       [0.06569676, 0.92592395, 0.02945699, 0.06553237],\n",
       "       [0.04116262, 0.9439624 , 0.03715816, 0.03738907],\n",
       "       [0.79255611, 0.107977  , 0.09641737, 0.07140144],\n",
       "       [0.16367296, 0.64600102, 0.10654277, 0.08342698],\n",
       "       [0.0658715 , 0.92309901, 0.03128572, 0.0529374 ],\n",
       "       [0.88450271, 0.06603439, 0.07525081, 0.0652722 ],\n",
       "       [0.10868271, 0.80949973, 0.05418003, 0.08367776],\n",
       "       [0.22750444, 0.38642051, 0.06507593, 0.22495175],\n",
       "       [0.06270281, 0.89080341, 0.0417685 , 0.05902119],\n",
       "       [0.17832948, 0.61133638, 0.04898271, 0.13843438],\n",
       "       [0.14693384, 0.2350578 , 0.09780335, 0.44281718],\n",
       "       [0.13069967, 0.48752997, 0.11251002, 0.16871067],\n",
       "       [0.26572788, 0.25223548, 0.1230989 , 0.21550459],\n",
       "       [0.03045322, 0.96286249, 0.03286275, 0.03699437],\n",
       "       [0.08805323, 0.67012206, 0.09792426, 0.14381256],\n",
       "       [0.1391964 , 0.75027987, 0.07021005, 0.09271027],\n",
       "       [0.1040607 , 0.6476369 , 0.07893598, 0.15069562],\n",
       "       [0.08002148, 0.7892737 , 0.06794823, 0.09316955],\n",
       "       [0.14788243, 0.62695868, 0.09040277, 0.09393811],\n",
       "       [0.9089269 , 0.05590244, 0.08348105, 0.03350637],\n",
       "       [0.04877585, 0.88396385, 0.08240386, 0.05011189],\n",
       "       [0.10785904, 0.73747251, 0.05843429, 0.12702951],\n",
       "       [0.06752829, 0.88623516, 0.04678681, 0.05941584],\n",
       "       [0.13142118, 0.65559976, 0.07234482, 0.13050099],\n",
       "       [0.72728552, 0.13437533, 0.08617818, 0.06183635],\n",
       "       [0.52863959, 0.20404712, 0.15482441, 0.06160108],\n",
       "       [0.13839089, 0.63923922, 0.08079575, 0.10107265],\n",
       "       [0.09606432, 0.79911776, 0.06348639, 0.07340633],\n",
       "       [0.35382567, 0.21140098, 0.27554365, 0.05526849],\n",
       "       [0.07838664, 0.82928403, 0.05471413, 0.07871055],\n",
       "       [0.12164386, 0.50456894, 0.06556747, 0.24251795],\n",
       "       [0.46034396, 0.27816724, 0.07589863, 0.10014781],\n",
       "       [0.05501282, 0.91331672, 0.0442939 , 0.04922512],\n",
       "       [0.05865425, 0.84335266, 0.06962827, 0.07671323],\n",
       "       [0.17310573, 0.47367657, 0.12719475, 0.11209344],\n",
       "       [0.06064146, 0.8677431 , 0.04690887, 0.07507439],\n",
       "       [0.86009138, 0.06762563, 0.10304432, 0.04521707],\n",
       "       [0.13735548, 0.57462401, 0.07168885, 0.1806984 ],\n",
       "       [0.24038433, 0.740744  , 0.03531032, 0.06809456],\n",
       "       [0.05033516, 0.64426078, 0.19834089, 0.09680017],\n",
       "       [0.04952839, 0.92081162, 0.03574734, 0.07054653],\n",
       "       [0.11604646, 0.8174263 , 0.05196148, 0.06663752],\n",
       "       [0.155037  , 0.21971449, 0.52447216, 0.07331625],\n",
       "       [0.17550943, 0.35693996, 0.11050126, 0.22331217],\n",
       "       [0.09226979, 0.61942719, 0.08567128, 0.18537296],\n",
       "       [0.08085268, 0.88824059, 0.03404807, 0.06959077],\n",
       "       [0.24944356, 0.28213197, 0.0817187 , 0.26098864],\n",
       "       [0.09857941, 0.60245078, 0.109503  , 0.13951641],\n",
       "       [0.06717826, 0.85992283, 0.06135853, 0.07467966],\n",
       "       [0.22311349, 0.71060423, 0.03932142, 0.08282272],\n",
       "       [0.24185573, 0.46657038, 0.06700167, 0.13895337],\n",
       "       [0.39596095, 0.35987964, 0.05639881, 0.1133558 ],\n",
       "       [0.86874616, 0.04729583, 0.09493495, 0.06854267],\n",
       "       [0.06327833, 0.811284  , 0.06199705, 0.10449621],\n",
       "       [0.43704138, 0.2631773 , 0.12386108, 0.07405678],\n",
       "       [0.96791055, 0.03426163, 0.05639509, 0.02691855],\n",
       "       [0.10937851, 0.71587741, 0.08665199, 0.08013639],\n",
       "       [0.08041163, 0.76845642, 0.05746017, 0.11257317],\n",
       "       [0.15213   , 0.65597768, 0.08384662, 0.08220241],\n",
       "       [0.08664488, 0.80908603, 0.0667185 , 0.0656383 ],\n",
       "       [0.09812251, 0.79845892, 0.0497203 , 0.08626758],\n",
       "       [0.31361955, 0.44296625, 0.04763283, 0.11481166],\n",
       "       [0.56043785, 0.41533266, 0.05411617, 0.04691112],\n",
       "       [0.13839089, 0.63923922, 0.08079575, 0.10107265],\n",
       "       [0.17743536, 0.66317773, 0.07226309, 0.09601428],\n",
       "       [0.08658232, 0.79966359, 0.06210242, 0.08238306],\n",
       "       [0.14132843, 0.63356535, 0.11080249, 0.09134868],\n",
       "       [0.19897358, 0.74407625, 0.02738332, 0.07989419],\n",
       "       [0.56918522, 0.1274806 , 0.17891525, 0.08555361],\n",
       "       [0.05290447, 0.91817705, 0.03975098, 0.05081721],\n",
       "       [0.07217715, 0.81509302, 0.09188088, 0.07094988],\n",
       "       [0.87001397, 0.07510632, 0.07115853, 0.05504389],\n",
       "       [0.43996073, 0.24807905, 0.09658369, 0.11022699],\n",
       "       [0.09006352, 0.63216021, 0.08636991, 0.18313402],\n",
       "       [0.09338046, 0.27790741, 0.39877059, 0.14133123],\n",
       "       [0.0601657 , 0.91859694, 0.04235302, 0.04430391],\n",
       "       [0.09198513, 0.73152643, 0.06624929, 0.11568113],\n",
       "       [0.39369317, 0.09147328, 0.52866288, 0.04047961],\n",
       "       [0.07411976, 0.82136476, 0.05370438, 0.09076132],\n",
       "       [0.07402093, 0.8748322 , 0.04399633, 0.07138446],\n",
       "       [0.08664488, 0.80908603, 0.0667185 , 0.0656383 ],\n",
       "       [0.15058186, 0.413206  , 0.22656916, 0.09091714]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_prob"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
